{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ig_RC_osmu_v001.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM3l8mau+LYDGzgEfBybsSx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/TesTime/blob/main/ig_RC_osmu_v001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO2DC7DXkDBA"
      },
      "source": [
        "# RC(Randomly Controled) 컨셉 테스트\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1pmXXiph59F",
        "outputId": "c0334c06-008c-4308-e65d-66d2935bfd8d"
      },
      "source": [
        "from datetime import datetime\n",
        "print(\"Current Date/Time: \", datetime.now())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Date/Time:  2021-05-07 07:45:47.472965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8qYYuBlkaEG"
      },
      "source": [
        "## Ignite 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbZKgCxHjZdp",
        "outputId": "d9b9a262-5bb7-4023-82d8-195349155de0"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d3/640f70d69393b415e6a29b27c735047ad86267921ad62682d1d756556d48/pytorch_ignite-0.4.4-py3-none-any.whl (200kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20kB 11.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 40kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71kB 5.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 81kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 102kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 112kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 122kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 133kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 153kB 6.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 163kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 174kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 184kB 6.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 194kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnzq_ghpj5EK"
      },
      "source": [
        "import os\n",
        "\n",
        "in_colab = \"COLAB_TPU_ADDR\" in os.environ\n",
        "with_torch_launch = \"WORLD_SIZE\" in os.environ\n",
        "\n",
        "if in_colab:\n",
        "    # https://github.com/pytorch/builder/pull/750\n",
        "    VERSION = \"20200607\" \n",
        "    #VERSION = \"nightly\"\n",
        "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "    !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5pfCKVpkBhw"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import datasets, models\n",
        "from torchvision.transforms import Compose, Normalize, Pad, RandomCrop, RandomHorizontalFlip, ToTensor\n",
        "\n",
        "import ignite.distributed as idist\n",
        "from ignite.contrib.engines import common\n",
        "from ignite.contrib.handlers import ProgressBar\n",
        "from ignite.engine import Engine, Events, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqUw795AkweY"
      },
      "source": [
        "train_transform = Compose(\n",
        "    [\n",
        "        Pad(4),\n",
        "        RandomCrop(32, fill=128),\n",
        "        RandomHorizontalFlip(),\n",
        "        ToTensor(),\n",
        "        Normalize((0.485, 0.456, 0.406), (0.229, 0.23, 0.225)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_transform = Compose([ToTensor(), Normalize((0.485, 0.456, 0.406), (0.229, 0.23, 0.225)),])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pHR2wPJlDjP"
      },
      "source": [
        "def get_train_test_datasets(path):\n",
        "    train_ds = datasets.CIFAR10(root=path, train=True, download=True, transform=train_transform)\n",
        "    test_ds = datasets.CIFAR10(root=path, train=False, download=False, transform=test_transform)\n",
        "\n",
        "    return train_ds, test_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DngCnmilJgP"
      },
      "source": [
        "def get_model(name):\n",
        "    if name in models.__dict__:\n",
        "        fn = models.__dict__[name]\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unknown model name {name}\")\n",
        "\n",
        "    return fn(num_classes=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ae11RRclNJL"
      },
      "source": [
        "def get_dataflow(config):\n",
        "\n",
        "    if idist.get_rank() > 0: # 마스터 노드만 데이터 다운로드\n",
        "        idist.barrier()\n",
        "\n",
        "    train_dataset, test_dataset = get_train_test_datasets(config.get(\"data_path\", \".\"))\n",
        "\n",
        "    if idist.get_rank() == 0: # 마스터 노드만 데이터 다운로드 \n",
        "        idist.barrier()\n",
        "\n",
        "    train_loader = idist.auto_dataloader(\n",
        "        train_dataset,\n",
        "        batch_size=config.get(\"batch_size\", 512),\n",
        "        num_workers=config.get(\"num_workers\", 8),\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    config[\"num_iters_per_epoch\"] = len(train_loader)\n",
        "\n",
        "    test_loader = idist.auto_dataloader(\n",
        "        test_dataset,\n",
        "        batch_size=2 * config.get(\"batch_size\", 512),\n",
        "        num_workers=config.get(\"num_workers\", 8),\n",
        "        shuffle=False,\n",
        "    )\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6CrLjmwlPln"
      },
      "source": [
        "def initialize(config):\n",
        "    \n",
        "    model = get_model(config[\"model\"])\n",
        "    model = idist.auto_model(model)\n",
        "\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=config.get(\"learning_rate\", 0.1),\n",
        "        momentum=config.get(\"momentum\", 0.9),\n",
        "        weight_decay=config.get(\"weight_decay\", 1e-5),\n",
        "        nesterov=True,\n",
        "    )\n",
        "    optimizer = idist.auto_optim(optimizer)\n",
        "    criterion = nn.CrossEntropyLoss().to(idist.device())\n",
        "\n",
        "    le = config[\"num_iters_per_epoch\"]\n",
        "    lr_scheduler = StepLR(optimizer, step_size=le, gamma=0.9)\n",
        "\n",
        "    return model, optimizer, criterion, lr_scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcuDSDG1lR4h"
      },
      "source": [
        "def create_trainer(model, optimizer, criterion, lr_scheduler, config):\n",
        "\n",
        "    def train_step(engine, batch):\n",
        "        x, y = batch[0].to(idist.device()), batch[1].to(idist.device())\n",
        "\n",
        "        model.train()\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    trainer = Engine(train_step)\n",
        "\n",
        "    if idist.get_rank() == 0:\n",
        "        @trainer.on(Events.ITERATION_COMPLETED(every=200))\n",
        "        def save_checkpoint():\n",
        "            fp = Path(config.get(\"output_path\", \"output\")) / \"checkpoint.pt\"\n",
        "            torch.save(model.state_dict(), fp)\n",
        "\n",
        "        # 진행 표시\n",
        "        ProgressBar().attach(trainer, output_transform=lambda x: {\"batch loss\": x})\n",
        "\n",
        "    return trainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsnN0_I1lUrH"
      },
      "source": [
        "def training(local_rank, config):\n",
        "\n",
        "    # 데이터 로더 처리\n",
        "    train_loader, val_loader = get_dataflow(config)\n",
        "    model, optimizer, criterion, lr_scheduler = initialize(config)\n",
        "\n",
        "    # 트레이너, 이밸류에이터 처리\n",
        "    trainer = create_trainer(model, optimizer, criterion, lr_scheduler, config)\n",
        "    evaluator = create_supervised_evaluator(model, metrics={\"accuracy\": Accuracy()}, device=idist.device())\n",
        "\n",
        "    # 에폭 관련 이벤트\n",
        "    @trainer.on(Events.EPOCH_COMPLETED(every=3))\n",
        "    def evaluate_model():\n",
        "        state = evaluator.run(val_loader)\n",
        "        if idist.get_rank() == 0:\n",
        "            print(state.metrics)\n",
        "\n",
        "    # 로그 처리\n",
        "    if idist.get_rank() == 0:\n",
        "        tb_logger = common.setup_tb_logging(\n",
        "            config.get(\"output_path\", \"output\"), trainer, optimizer, evaluators={\"validation\": evaluator},\n",
        "        )\n",
        "\n",
        "    # 트레이터 실행\n",
        "    trainer.run(train_loader, max_epochs=config.get(\"max_epochs\", 3))\n",
        "\n",
        "    if idist.get_rank() == 0:\n",
        "        tb_logger.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8OXLrk0lYSF"
      },
      "source": [
        "\n",
        "# xxx\n",
        "if __name__ == \"__main__\" and not (in_colab or with_torch_launch):\n",
        "\n",
        "    backend = None  # or \"nccl\", \"gloo\", \"xla-tpu\" ...\n",
        "    nproc_per_node = None  # or N to spawn N processes\n",
        "    config = {\n",
        "        \"model\": \"resnet18\",\n",
        "        \"dataset\": \"cifar10\",\n",
        "    }\n",
        "\n",
        "    with idist.Parallel(backend=backend, nproc_per_node=nproc_per_node) as parallel:\n",
        "        parallel.run(training, config)\n",
        "\n",
        "\n",
        "# GPU\n",
        "if __name__ == \"__main__\" and with_torch_launch:\n",
        "\n",
        "    backend = \"nccl\"  # or \"nccl\", \"gloo\", \"xla-tpu\" ...\n",
        "    nproc_per_node = None  # or N to spawn N processes\n",
        "    config = {\n",
        "        \"model\": \"resnet18\",\n",
        "        \"dataset\": \"cifar10\",\n",
        "    }\n",
        "\n",
        "    with idist.Parallel(backend=backend, nproc_per_node=nproc_per_node) as parallel:\n",
        "        parallel.run(training, config)\n",
        "\n",
        "\n",
        "# TPU\n",
        "if in_colab:\n",
        "    \n",
        "    backend = \"xla-tpu\"  # or \"nccl\", \"gloo\", \"xla-tpu\" ...\n",
        "    #nproc_per_node = 2  # xxx\n",
        "    nproc_per_node = 8  # 8 TPU (장당 4코어, 2장까지 지원)\n",
        "    config = {\n",
        "        \"model\": \"resnet18\",\n",
        "        \"dataset\": \"cifar10\",\n",
        "    }\n",
        "\n",
        "    with idist.Parallel(backend=backend, nproc_per_node=nproc_per_node) as parallel:\n",
        "        parallel.run(training, config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxdJb2u-u6Va"
      },
      "source": [
        "%debug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40uPkPoolcgb"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmuf3es8oqH4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}