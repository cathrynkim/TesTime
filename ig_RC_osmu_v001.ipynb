{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ig_RC_osmu_v001.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMrVfZWKOJrUMTdsq3+SI/6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e6f95fe3ff834074ad242b0c77065953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_edf4666039dd4098b8a8a1ada031e965",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d893404ff65f46c3a2a2b18b11c0b8a5",
              "IPY_MODEL_70c45c078d4641768bfdb8fdadd040d0"
            ]
          }
        },
        "edf4666039dd4098b8a8a1ada031e965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d893404ff65f46c3a2a2b18b11c0b8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f3d09be81ca9486894e9529cac7d9d5a",
            "_dom_classes": [],
            "description": "Epoch [1/3]: [97/97] 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 97,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 97,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3154d98221641509c07a5d3758eecef"
          }
        },
        "70c45c078d4641768bfdb8fdadd040d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f29c6479d9d44b1da738da25d7862425",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", batch loss=2.32 [00:30&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d59d1b8a5b354af086a9156cc9e7aad9"
          }
        },
        "f3d09be81ca9486894e9529cac7d9d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3154d98221641509c07a5d3758eecef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f29c6479d9d44b1da738da25d7862425": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d59d1b8a5b354af086a9156cc9e7aad9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f41f3af91654bc185688635ef6e5299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5bba92ecda4a44118928eacef64ad89c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a733eee929e447786918bf8210576d4",
              "IPY_MODEL_88c1786083b74dc78824c6266f85a950"
            ]
          }
        },
        "5bba92ecda4a44118928eacef64ad89c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a733eee929e447786918bf8210576d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_605115204ca6476987831626a4dc0172",
            "_dom_classes": [],
            "description": "Epoch [2/3]: [97/97] 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 97,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 97,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_685f7897e307409aa153676c939f7bb6"
          }
        },
        "88c1786083b74dc78824c6266f85a950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ccfe8749b804d9f8b7195594b9448df",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", batch loss=1.5 [00:37&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c86720edd042403682c3f7ec99a217ec"
          }
        },
        "605115204ca6476987831626a4dc0172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "685f7897e307409aa153676c939f7bb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ccfe8749b804d9f8b7195594b9448df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c86720edd042403682c3f7ec99a217ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c73eaea2b8a047b4a6d86327e150a4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9e487ba4b3d4ca8a61766752b9c5869",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ef69324a1d5401ea41515b78a0644f3",
              "IPY_MODEL_acdd77f271e84023a7b4ef59f9c9bb44"
            ]
          }
        },
        "f9e487ba4b3d4ca8a61766752b9c5869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ef69324a1d5401ea41515b78a0644f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38665801162b4a93baa8155a17939517",
            "_dom_classes": [],
            "description": "Epoch [3/3]: [97/97] 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 97,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 97,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8429a52a23e64f8ea28c93eea6a50215"
          }
        },
        "acdd77f271e84023a7b4ef59f9c9bb44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73e91471c2764932b8d3362c14a24f4f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": ", batch loss=1.55 [00:31&lt;00:00]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3480e43a1855400b96967078902ca8ac"
          }
        },
        "38665801162b4a93baa8155a17939517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8429a52a23e64f8ea28c93eea6a50215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73e91471c2764932b8d3362c14a24f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3480e43a1855400b96967078902ca8ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secutron/TesTime/blob/main/ig_RC_osmu_v001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO2DC7DXkDBA"
      },
      "source": [
        "# RC(Randomly Controled) 컨셉 테스트\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1pmXXiph59F",
        "outputId": "d9c6c53c-156a-4417-f537-181b3f91d328"
      },
      "source": [
        "from datetime import datetime\n",
        "print(\"Current Date and Time: \", datetime.now())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current Date and Time:  2021-05-11 22:57:31.605623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8qYYuBlkaEG"
      },
      "source": [
        "## Ignite 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbZKgCxHjZdp",
        "outputId": "ab578e7f-d2be-4669-c62b-00a8824a2786"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d3/640f70d69393b415e6a29b27c735047ad86267921ad62682d1d756556d48/pytorch_ignite-0.4.4-py3-none-any.whl (200kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20kB 20.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 10.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 81kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 102kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 112kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 122kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 133kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 153kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 163kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 174kB 5.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 184kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 194kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.19.5)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bnzq_ghpj5EK",
        "outputId": "8a7e9a3b-44f0-4e91-b4f8-398a0da02f4d"
      },
      "source": [
        "import os\n",
        "\n",
        "in_colab = \"COLAB_TPU_ADDR\" in os.environ\n",
        "with_torch_launch = \"WORLD_SIZE\" in os.environ\n",
        "\n",
        "if in_colab:\n",
        "    # https://github.com/pytorch/builder/pull/750\n",
        "    VERSION = \"20200607\" \n",
        "    #VERSION = \"nightly\"\n",
        "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "    !python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  5116  100  5116    0     0  21863      0 --:--:-- --:--:-- --:--:-- 21770\n",
            "Updating... This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200607 ...\n",
            "Collecting cloud-tpu-client\n",
            "  Downloading https://files.pythonhosted.org/packages/56/9f/7b1958c2886db06feb5de5b2c191096f9e619914b6c31fdf93999fdbbd8b/cloud_tpu_client-0.10-py3-none-any.whl\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from cloud-tpu-client) (4.1.3)\n",
            "Collecting google-api-python-client==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/b4/a955f393b838bc47cbb6ae4643b9d0f90333d3b4db4dc1e819f36aad18cc/google_api_python_client-1.8.0-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (1.15.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (0.17.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->cloud-tpu-client) (4.7.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.26.3)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client==1.8.0->cloud-tpu-client) (1.28.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2018.9)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.12.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.53.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (20.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (56.1.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client) (4.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.13.0->google-api-python-client==1.8.0->cloud-tpu-client) (2.4.7)\n",
            "Uninstalling torch-1.8.1+cu101:\n",
            "\u001b[31mERROR: earthengine-api 0.1.260 has requirement google-api-python-client<2,>=1.12.1, but you'll have google-api-python-client 1.8.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-api-python-client, cloud-tpu-client\n",
            "  Found existing installation: google-api-python-client 1.12.8\n",
            "    Uninstalling google-api-python-client-1.12.8:\n",
            "      Successfully uninstalled google-api-python-client-1.12.8\n",
            "Successfully installed cloud-tpu-client-0.10 google-api-python-client-1.8.0\n",
            "Done updating TPU runtime\n",
            "  Successfully uninstalled torch-1.8.1+cu101\n",
            "Uninstalling torchvision-0.9.1+cu101:\n",
            "  Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200607-cp37-cp37m-linux_x86_64.whl...\n",
            "\\ [1 files][ 89.5 MiB/ 89.5 MiB]                                                \n",
            "Operation completed over 1 objects/89.5 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200607-cp37-cp37m-linux_x86_64.whl...\n",
            "\\ [1 files][116.9 MiB/116.9 MiB]                                                \n",
            "Operation completed over 1 objects/116.9 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200607-cp37-cp37m-linux_x86_64.whl...\n",
            "/ [1 files][  1.7 MiB/  1.7 MiB]                                                \n",
            "Operation completed over 1 objects/1.7 MiB.                                      \n",
            "Processing ./torch-nightly+20200607-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20200607) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==nightly+20200607) (1.19.5)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.6.0a0+a25b1b9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+a25b1b9\n",
            "Processing ./torch_xla-nightly+20200607-cp37-cp37m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+407518\n",
            "Processing ./torchvision-nightly+20200607-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200607) (7.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200607) (1.6.0a0+a25b1b9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==nightly+20200607) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->torchvision==nightly+20200607) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+3e06bc6\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (332 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5pfCKVpkBhw"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import datasets, models\n",
        "from torchvision.transforms import Compose, Normalize, Pad, RandomCrop, RandomHorizontalFlip, ToTensor\n",
        "\n",
        "import ignite.distributed as idist\n",
        "from ignite.contrib.engines import common\n",
        "from ignite.contrib.handlers import ProgressBar\n",
        "from ignite.engine import Engine, Events, create_supervised_evaluator\n",
        "from ignite.metrics import Accuracy\n",
        "from ignite.utils import manual_seed, setup_logger"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3_WFtKm8BU_"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsCYlqli4iMV"
      },
      "source": [
        "def get_MNIST(path=\"./\"):\n",
        "    input_size = 28\n",
        "    num_classes = 10\n",
        "    \n",
        "    transform = Compose(\n",
        "        [ToTensor(), Normalize((0.1307,), (0.3081,))]\n",
        "        )\n",
        "\n",
        "    train_dataset = datasets.MNIST(path + \"data/\", train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.MNIST(path + \"data/\", train=False, download=True, transform=transform)\n",
        "\n",
        "    return input_size, num_classes, train_dataset, test_dataset\n",
        "\n",
        "\n",
        "def get_FashionMNIST(path=\"./\"):\n",
        "    input_size = 28\n",
        "    num_classes = 10\n",
        "\n",
        "    transform = Compose(\n",
        "        [ToTensor(), Normalize((0.2861,), (0.3530,))]\n",
        "        )\n",
        "\n",
        "    train_dataset = datasets.FashionMNIST(path + \"data/\", train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.FashionMNIST(path + \"data/\", train=False, download=True, transform=transform\n",
        "                                         )\n",
        "    return input_size, num_classes, train_dataset, test_dataset\n",
        "\n",
        "\n",
        "def get_SVHN(path=\"./\"):\n",
        "    input_size = 32\n",
        "    num_classes = 10\n",
        "\n",
        "    transform = Compose(\n",
        "        [ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "        )\n",
        "\n",
        "    train_dataset = datasets.SVHN(path + \"data/SVHN\", split=\"train\", transform=transform, download=True)\n",
        "    test_dataset = datasets.SVHN(path + \"data/SVHN\", split=\"test\", transform=transform, download=True)\n",
        "\n",
        "    return input_size, num_classes, train_dataset, test_dataset\n",
        "\n",
        "\n",
        "def get_CIFAR10(path=\"./\"):\n",
        "    input_size = 32\n",
        "    num_classes = 10\n",
        "    train_transform = Compose(\n",
        "        [\n",
        "            #            Pad(4),\n",
        "            RandomCrop(32, fill=128, padding=4),\n",
        "            RandomHorizontalFlip(),\n",
        "            ToTensor(),\n",
        "            Normalize((0.485, 0.456, 0.406), (0.229, 0.23, 0.225)),\n",
        "        ]\n",
        "        )\n",
        "    \n",
        "    train_dataset = datasets.CIFAR10(path + \"data/CIFAR10\", train=True, transform=train_transform, download=True)\n",
        "\n",
        "    test_transform = Compose(\n",
        "        [\n",
        "            ToTensor(),\n",
        "            Normalize((0.485, 0.456, 0.406), (0.229, 0.23, 0.225)),\n",
        "        ]\n",
        "        )\n",
        "    \n",
        "    test_dataset = datasets.CIFAR10(path + \"data/CIFAR10\", train=False, transform=test_transform, download=True)\n",
        "\n",
        "    return input_size, num_classes, train_dataset, test_dataset\n",
        "\n",
        "\n",
        "def get_notMNIST(path=\"./\"):\n",
        "    input_size = 28\n",
        "    num_classes = 10\n",
        "\n",
        "    transform = Compose(\n",
        "        [ToTensor(), Normalize((0.4254,), (0.4586,))]\n",
        "        )\n",
        "\n",
        "    test_dataset = NotMNIST(path + \"data/\", transform=transform)\n",
        "\n",
        "    return input_size, num_classes, None, test_dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bG896Yd4ckj"
      },
      "source": [
        "all_datasets = {\n",
        "    \"MNIST\": get_MNIST,\n",
        "    \"notMNIST\": get_notMNIST,\n",
        "    \"FashionMNIST\": get_FashionMNIST,\n",
        "    \"SVHN\": get_SVHN,\n",
        "    \"CIFAR10\": get_CIFAR10,\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LOQ8sn64b15"
      },
      "source": [
        "class NotMNIST(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        root = os.path.expanduser(root)\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        data_dict = loadmat(os.path.join(root, \"notMNIST_small.mat\"))\n",
        "\n",
        "        self.data = torch.tensor(\n",
        "            data_dict[\"images\"].transpose(2, 0, 1), dtype=torch.uint8\n",
        "        ).unsqueeze(1)\n",
        "\n",
        "        self.targets = torch.tensor(data_dict[\"labels\"], dtype=torch.int64)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = self.data[index]\n",
        "        target = self.targets[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            img = Image.fromarray(img.squeeze().numpy(), mode=\"L\")\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "\n",
        "class FastFashionMNIST(datasets.FashionMNIST):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.data = self.data.unsqueeze(1).float().div(255)\n",
        "        self.data = self.data.sub_(0.2861).div_(0.3530)\n",
        "\n",
        "        self.data, self.targets = self.data.to(\"cuda\"), self.targets.to(\"cuda\")\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index (int): Index\n",
        "        Returns:\n",
        "            tuple: (image, target) where target is index of the target class.\n",
        "        \"\"\"\n",
        "        img, target = self.data[index], self.targets[index]\n",
        "\n",
        "        return img, target"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pHR2wPJlDjP"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DngCnmilJgP"
      },
      "source": [
        "def get_model(name):\n",
        "    if name in models.__dict__:\n",
        "        fn = models.__dict__[name]\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unknown model name {name}\")\n",
        "\n",
        "    return fn(num_classes=10)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ae11RRclNJL"
      },
      "source": [
        "def get_dataflow(config):\n",
        "\n",
        "    if idist.get_rank() > 0: # 마스터 노드만 데이터 다운로드\n",
        "        idist.barrier()\n",
        "\n",
        "    dataset_name = config.get(\"dataset\", \"cifar10\")\n",
        "    if dataset_name == \"cifar10\":\n",
        "        #train_dataset, test_dataset = get_train_test_datasets(config.get(\"data_path\", \".\"))\n",
        "        input_size, num_classes, train_dataset, test_dataset = all_datasets[\"CIFAR10\"]()\n",
        "    else: \n",
        "        # never happen.\n",
        "        raise RuntimeError(f\"Unknown dataset_name {dataset_name}\")\n",
        "\n",
        "    if idist.get_rank() == 0: # 마스터 노드만 데이터 다운로드 \n",
        "        idist.barrier()\n",
        "\n",
        "    train_loader = idist.auto_dataloader(\n",
        "        train_dataset,\n",
        "        batch_size=config.get(\"batch_size\", 512),\n",
        "        num_workers=config.get(\"num_workers\", 8),\n",
        "        shuffle=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    config[\"num_iters_per_epoch\"] = len(train_loader)\n",
        "\n",
        "    test_loader = idist.auto_dataloader(\n",
        "        test_dataset,\n",
        "        batch_size=2 * config.get(\"batch_size\", 512),\n",
        "        num_workers=config.get(\"num_workers\", 8),\n",
        "        shuffle=False,\n",
        "    )\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6CrLjmwlPln"
      },
      "source": [
        "def initialize(config):\n",
        "    \n",
        "    model = get_model(config[\"model\"])\n",
        "    model = idist.auto_model(model)\n",
        "\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=config.get(\"learning_rate\", 0.1),\n",
        "        momentum=config.get(\"momentum\", 0.9),\n",
        "        weight_decay=config.get(\"weight_decay\", 1e-5),\n",
        "        nesterov=True,\n",
        "    )\n",
        "    optimizer = idist.auto_optim(optimizer)\n",
        "    criterion = nn.CrossEntropyLoss().to(idist.device())\n",
        "\n",
        "    le = config[\"num_iters_per_epoch\"]\n",
        "    lr_scheduler = StepLR(optimizer, step_size=le, gamma=0.9)\n",
        "\n",
        "    return model, optimizer, criterion, lr_scheduler"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcuDSDG1lR4h"
      },
      "source": [
        "def create_trainer(model, optimizer, criterion, lr_scheduler, config):\n",
        "\n",
        "    def train_step(engine, batch):\n",
        "        x, y = batch[0].to(idist.device()), batch[1].to(idist.device())\n",
        "\n",
        "        model.train()\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        return loss.item()\n",
        "\n",
        "    trainer = Engine(train_step)\n",
        "\n",
        "    if idist.get_rank() == 0:\n",
        "        @trainer.on(Events.ITERATION_COMPLETED(every=200))\n",
        "        def save_checkpoint():\n",
        "            fp = Path(config.get(\"output_path\", \"output\")) / \"checkpoint.pt\"\n",
        "            torch.save(model.state_dict(), fp)\n",
        "\n",
        "        # 진행 표시\n",
        "        ProgressBar().attach(trainer, output_transform=lambda x: {\"batch loss\": x})\n",
        "\n",
        "    return trainer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsnN0_I1lUrH"
      },
      "source": [
        "def training(local_rank, config):\n",
        "    # spawn 된 경우를 생각하고 또 생각할 것\n",
        "\n",
        "\n",
        "    # 모든 프로세스에서 한번씩 표시\n",
        "    print(idist.get_rank(), \": run with config:\", config, \"- backend=\", idist.backend())\n",
        "    \n",
        "    # 글로벌 랭크로 연결된 로거에 표시\n",
        "    logger = setup_logger(\"ig_RC_osmu\", distributed_rank=idist.get_rank())\n",
        "    logger.info(f\"rank: {idist.get_rank()}\")\n",
        "\n",
        "    # 로컬 랭크(해당 노드에서의 프로세스 id)에 연결된 로거에 표시\n",
        "    # 단일 노드인 경우에는!!! \n",
        "    logger2 = setup_logger(\"ig_RC_osmu\")\n",
        "    logger2.info(f\"local rank: '{idist.get_local_rank()}\")\n",
        "\n",
        "\n",
        "    # 데이터 로더 처리\n",
        "    train_loader, val_loader = get_dataflow(config)\n",
        "    model, optimizer, criterion, lr_scheduler = initialize(config)\n",
        "\n",
        "    # 트레이너, 이밸류에이터 처리\n",
        "    trainer = create_trainer(model, optimizer, criterion, lr_scheduler, config)\n",
        "    evaluator = create_supervised_evaluator(model, metrics={\"accuracy\": Accuracy()}, device=idist.device())\n",
        "\n",
        "\n",
        "    # 에폭 관련 이벤트\n",
        "    @trainer.on(Events.EPOCH_COMPLETED(every=3))\n",
        "    def evaluate_model():\n",
        "        state = evaluator.run(val_loader)\n",
        "        if idist.get_rank() == 0:\n",
        "            print(f\"eval metric: {state.metrics}\")\n",
        "    '''\n",
        "    # 프로파일 - 싱글 에폭 소요\n",
        "    @trainer.on(Events.EPOCH_COMPLETED)\n",
        "    def log_epoch_time():\n",
        "        print(f\"rank: {idist.get_rank()}, epoch: {trainer.state.epoch} - {trainer.state.times['EPOCH_COMPLETED']}\")\n",
        "    '''\n",
        "    @trainer.on(Events.COMPLETED)\n",
        "    # 프로파일 - 전체 학습 소요\n",
        "    def log_total_time():\n",
        "        print(f\"rank: {idist.get_rank()}, total: {trainer.state.times['COMPLETED']}\")\n",
        "\n",
        "    '''\n",
        "    # 베이직/핸들러 타임 프로파일링\n",
        "    if config[\"profile\"] is True:\n",
        "        #from ignite.contrib.handlers import BasicTimeProfiler\n",
        "        #profiler = BasicTimeProfiler()\n",
        "\n",
        "        from ignite.contrib.handlers import HandlersTimeProfiler\n",
        "        profiler = HandlersTimeProfiler()\n",
        "\n",
        "        profiler.attach(trainer)\n",
        "\n",
        "        @trainer.on(Events.EPOCH_COMPLETED(every=3))\n",
        "        def log_intermediate_results():\n",
        "            profiler.print_results(profiler.get_results())\n",
        "    '''\n",
        "\n",
        "    # 로그 처리\n",
        "    if idist.get_rank() == 0:\n",
        "        tb_logger = common.setup_tb_logging(\n",
        "            config.get(\"output_path\", \"output\"), trainer, optimizer, evaluators={\"validation\": evaluator},\n",
        "        )\n",
        "\n",
        "    # 트레이터 실행\n",
        "    trainer.run(train_loader, max_epochs=config.get(\"max_epochs\", 3))\n",
        "\n",
        "    if idist.get_rank() == 0:\n",
        "        tb_logger.close()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neiClyAzywho",
        "outputId": "75b6dc5b-a0fe-4247-a93f-55dd7817c75c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"*************************************\")\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the comment above for instructions!')\n",
        "\n",
        "print(\"\\n*** connect to cluster\")\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "\n",
        "print(\"\\n*** initialize tpu\")\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "# tpu 0번부터 7번까지 배정 : thank Google!!!\n",
        "# host(master)로 cpu 0번, worker로 다시 cpu 0번, worker에 딸린 tpu가 0번부터 7번으로 8개\n",
        "print(\"\\n*** tpu strategy\")\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "*************************************\n",
            "Tensorflow version 2.4.1\n",
            "\n",
            "\n",
            "Running on TPU  ['10.105.20.242:8470']\n",
            "\n",
            "*** connect to cluster\n",
            "\n",
            "*** initialize tpu\n",
            "WARNING:tensorflow:TPU system grpc://10.105.20.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.105.20.242:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.105.20.242:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.105.20.242:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** tpu strategy\n",
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e6f95fe3ff834074ad242b0c77065953",
            "edf4666039dd4098b8a8a1ada031e965",
            "d893404ff65f46c3a2a2b18b11c0b8a5",
            "70c45c078d4641768bfdb8fdadd040d0",
            "f3d09be81ca9486894e9529cac7d9d5a",
            "f3154d98221641509c07a5d3758eecef",
            "f29c6479d9d44b1da738da25d7862425",
            "d59d1b8a5b354af086a9156cc9e7aad9",
            "4f41f3af91654bc185688635ef6e5299",
            "5bba92ecda4a44118928eacef64ad89c",
            "6a733eee929e447786918bf8210576d4",
            "88c1786083b74dc78824c6266f85a950",
            "605115204ca6476987831626a4dc0172",
            "685f7897e307409aa153676c939f7bb6",
            "5ccfe8749b804d9f8b7195594b9448df",
            "c86720edd042403682c3f7ec99a217ec",
            "c73eaea2b8a047b4a6d86327e150a4b0",
            "f9e487ba4b3d4ca8a61766752b9c5869",
            "3ef69324a1d5401ea41515b78a0644f3",
            "acdd77f271e84023a7b4ef59f9c9bb44",
            "38665801162b4a93baa8155a17939517",
            "8429a52a23e64f8ea28c93eea6a50215",
            "73e91471c2764932b8d3362c14a24f4f",
            "3480e43a1855400b96967078902ca8ac"
          ]
        },
        "id": "t8OXLrk0lYSF",
        "outputId": "9defac57-ed15-4717-b945-46809a57079e"
      },
      "source": [
        "# 멀티노드 launch 유틸: 각 nodes에서 실행\n",
        "# https://pytorch.org/ignite/v0.4.4.post1/distributed.html#ignite-distributed-launcher\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"*************************************\")\n",
        "print(\"Ignite : 멀티노드 경우는 고려되지 않음 by hkim 11MAY21\")\n",
        "print(\"\\n\")\n",
        "\n",
        "config = {\n",
        "    \"profile\": True,\n",
        "    \"model\": \"resnet18\",\n",
        "    \"dataset\": \"cifar10\",\n",
        "}\n",
        "\n",
        "# xxx\n",
        "if __name__ == \"__main__\" and not (in_colab or with_torch_launch):\n",
        "\n",
        "    backend = None  # or \"nccl\", \"gloo\", \"xla-tpu\" ...\n",
        "    nproc_per_node = None  # or N to spawn N processes\n",
        "\n",
        "    with idist.Parallel(backend=backend, nproc_per_node=nproc_per_node) as parallel:\n",
        "        parallel.run(training, config)\n",
        "\n",
        "\n",
        "# GPU\n",
        "if __name__ == \"__main__\" and with_torch_launch:\n",
        "\n",
        "    backend = \"nccl\"  # or \"nccl\", \"gloo\", \"xla-tpu\" ...\n",
        "    nproc_per_node = None  # or N to spawn N processes\n",
        "\n",
        "    with idist.Parallel(backend=backend, nproc_per_node=nproc_per_node) as parallel:\n",
        "        parallel.run(training, config)\n",
        "\n",
        "\n",
        "# TPU\n",
        "if in_colab:\n",
        "    \n",
        "    backend = \"xla-tpu\"  # or \"nccl\", \"gloo\", \"xla-tpu\" ...\n",
        "    #nproc_per_node = 1  # xxx\n",
        "    nproc_per_node = 8  # 8 TPU (4칩 x 2코어까지 지원)\n",
        "\n",
        "    # Parallel: Distributed launcher context manager\n",
        "    # https://pytorch.org/ignite/distributed.html#ignite-distributed-launcher\n",
        "    # Multi-node option : 2 nodes with 8 GPUs each 참고할 것\n",
        "    # 예: python -m torch.distributed.launch --nnodes=2 --node_rank=0 --master_addr=master                 \n",
        "    #     --master_port=3344 --nproc_per_node=8 --use_env main.py\n",
        "    # spawn param이 설정되는 경우 확인할 것.\n",
        "\n",
        "    from time import time\n",
        "    start = time()\n",
        "    with idist.Parallel(backend=backend, nproc_per_node=nproc_per_node) as parallel:\n",
        "        parallel.run(training, config)\n",
        "    end = time()\n",
        "    print(f\"Elapsed time: {end-start}\")\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-12 00:46:03,725 ignite.distributed.launcher.Parallel INFO: Initialized distributed launcher with backend: 'xla-tpu'\n",
            "2021-05-12 00:46:03,727 ignite.distributed.launcher.Parallel INFO: - Parameters to spawn processes: \n",
            "\tnproc_per_node: 8\n",
            "\tnnodes: 1\n",
            "\tnode_rank: 0\n",
            "2021-05-12 00:46:03,730 ignite.distributed.launcher.Parallel INFO: Spawn function '<function training at 0x7fccb3d015f0>' in 8 processes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "*************************************\n",
            "Ignite : 멀티노드 경우는 고려되지 않음 by hkim 11MAY21\n",
            "\n",
            "\n",
            "0 : run with config: {'profile': True, 'model': 'resnet18', 'dataset': 'cifar10'} - backend= xla-tpu\n",
            "1 : run with config: {'profile': True, 'model': 'resnet18', 'dataset': 'cifar10'} - backend= xla-tpu\n",
            "5 : run with config: {'profile': True, 'model': 'resnet18', 'dataset': 'cifar10'} - backend= xla-tpu\n",
            "3 : run with config: {'profile': True, 'model': 'resnet18', 'dataset': 'cifar10'} - backend= xla-tpu\n",
            "4 : run with config: {'profile': True, 'model': 'resnet18', 'dataset': 'cifar10'} - backend= xla-tpu\n",
            "7 : run with config: {'profile': True, 'model': 'resnet18', 'dataset': 'cifar10'} - backend= xla-tpu\n",
            "6 : run with config: {'profile': True, 'model': 'resnet18', 'dataset': 'cifar10'} - backend= xla-tpu\n",
            "2 : run with config: {'profile': True, 'model': 'resnet18', 'dataset': 'cifar10'} - backend= xla-tpu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-12 00:46:49,496 ig_RC_osmu INFO: rank: 0\n",
            "2021-05-12 00:46:49,516 ig_RC_osmu INFO: local rank: '0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-12 00:46:51,931 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': \n",
            "\t{'batch_size': 64, 'num_workers': 1, 'drop_last': True, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x7fccb3cafc90>, 'pin_memory': False}\n",
            "2021-05-12 00:46:51,978 ignite.distributed.auto.auto_dataloader INFO: DataLoader is wrapped by `MpDeviceLoader` on XLA\n",
            "2021-05-12 00:46:52,002 ignite.distributed.auto.auto_dataloader INFO: Use data loader kwargs for dataset 'Dataset CIFAR10': \n",
            "\t{'batch_size': 128, 'num_workers': 1, 'sampler': <torch.utils.data.distributed.DistributedSampler object at 0x7fccb3caf850>, 'pin_memory': False}\n",
            "2021-05-12 00:46:52,014 ignite.distributed.auto.auto_dataloader INFO: DataLoader is wrapped by `MpDeviceLoader` on XLA\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6f95fe3ff834074ad242b0c77065953",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=97.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4f41f3af91654bc185688635ef6e5299",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=97.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c73eaea2b8a047b4a6d86327e150a4b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=97.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\rrank: 2, total: 108.41035032272339\n",
            "rank: 1, total: 107.66651630401611\n",
            "rank: 3, total: 107.72936391830444\n",
            "rank: 7, total: 107.87349462509155\n",
            "rank: 6, total: 108.32522249221802\n",
            "eval metric: {'accuracy': 0.5149}\n",
            "rank: 4, total: 107.7634961605072\n",
            "rank: 5, total: 108.06047916412354\n",
            "rank: 0, total: 120.23467087745667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-05-12 00:48:54,762 ignite.distributed.launcher.Parallel INFO: End of run\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Elapsed time: 171.03995394706726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40uPkPoolcgb"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmuf3es8oqH4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}